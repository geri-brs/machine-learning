{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zoo_animals_classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMXiAByYSClP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %matplotlib inline\n",
        "import numpy\n",
        "import pandas            as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow        as tf\n",
        "from   tensorflow                 import keras\n",
        "from   tensorflow.keras           import layers\n",
        "from   tensorflow.keras.callbacks import EarlyStopping\n",
        "from   sklearn.preprocessing      import LabelEncoder, OneHotEncoder\n",
        "from   sklearn.model_selection    import train_test_split\n",
        "from   sklearn.ensemble           import ExtraTreesClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kzQkWMgSawX",
        "colab_type": "code",
        "outputId": "791bc81e-5514-4bb0-cc8b-ecfe4a2654df",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "source": [
        "# Upload dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-644c32e4-02cc-478f-9f97-131b55d750d9\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-644c32e4-02cc-478f-9f97-131b55d750d9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving zoo.csv to zoo.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuuUzZSJSjJg",
        "colab_type": "code",
        "outputId": "a7393dd9-66d7-4d3d-f427-c9deb436039b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(\"Versions:\")\n",
        "print(\"Tensorflow:\", tf.VERSION)\n",
        "# 1.14.0-rc1\n",
        "print(\"Keras: \", tf.keras.__version__)\n",
        "#2.2.4-tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Versions:\n",
            "Tensorflow: 1.14.0\n",
            "Keras:  2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt2I-2udSlDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load iris dataset\n",
        "path = \"./zoo.csv\"\n",
        "dataset = pd.read_csv(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9apQKIBbSn_G",
        "colab_type": "code",
        "outputId": "bd7f3961-09a7-4a71-94aa-41772b90552d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>animal_name</th>\n",
              "      <th>hair</th>\n",
              "      <th>feathers</th>\n",
              "      <th>eggs</th>\n",
              "      <th>milk</th>\n",
              "      <th>airborne</th>\n",
              "      <th>aquatic</th>\n",
              "      <th>predator</th>\n",
              "      <th>toothed</th>\n",
              "      <th>backbone</th>\n",
              "      <th>breathes</th>\n",
              "      <th>venomous</th>\n",
              "      <th>fins</th>\n",
              "      <th>legs</th>\n",
              "      <th>tail</th>\n",
              "      <th>domestic</th>\n",
              "      <th>catsize</th>\n",
              "      <th>class_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aardvark</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>antelope</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bass</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bear</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>boar</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  animal_name  hair  feathers  eggs  ...  tail  domestic  catsize  class_type\n",
              "0    aardvark     1         0     0  ...     0         0        1           1\n",
              "1    antelope     1         0     0  ...     1         0        1           1\n",
              "2        bass     0         0     1  ...     1         0        0           4\n",
              "3        bear     1         0     0  ...     0         0        1           1\n",
              "4        boar     1         0     0  ...     1         0        1           1\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW-KVXJvv-Ou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = dataset[\"class_type\"]\n",
        "\n",
        "# Remove unnecessary columns\n",
        "del dataset[\"animal_name\"]\n",
        "del dataset[\"class_type\"]\n",
        "del dataset[\"catsize\"]\n",
        "del dataset[\"domestic\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYEwIWEyv8V-",
        "colab_type": "code",
        "outputId": "7041913f-1a05-4a50-a99b-474426feb4a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "# Feature selection (feature importance)\n",
        "print(dataset.shape)\n",
        "\n",
        "X = pd.DataFrame.copy(dataset)\n",
        "model = ExtraTreesClassifier()\n",
        "model.fit(X,y)\n",
        "\n",
        "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
        "feat_importances.nlargest(25).plot(kind='barh')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(101, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAD8CAYAAAChHgmuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHklJREFUeJzt3XmYXWWd7fHvIkAgBBOU6A0RiTKI\nQEiAAgWRBpumvYKiAo0GR7jmcsXG4aLQDXZHm6so2ioqYlBuVBBpaEEalcE0kxGEJJAJCCjBlkFQ\n5oAgJKv/2G+ZQ1FznV3nnLA+z1NP7bPPHn470y/vPrveJdtERETUab1WFxAREeu+NJuIiKhdmk1E\nRNQuzSYiImqXZhMREbVLs4mIiNql2URERO3SbCIionZpNhERUbv1W11Au9h88809derUVpcREdFR\nFi5c+EfbkwbaLs2mmDp1KgsWLGh1GRERHUXSbwezXW6jRURE7dJsIiKidm15G03SKtvj+3l/IjDT\n9unNOufSex5l6gk/adbhBuWuUw4c1fNFRLTKqI1sJI1p4uEmAh8a4vnbsrFGRLwQNKXZSJoq6TZJ\n50i6VdIFksZJukvS5yUtAg6TtLWkSyUtlHStpO3L/q+UdJ2kpZJObjjueEnzJC0q7x1c3joF2FrS\nzZJOVeVUScvKdoeX/fct57kYuKUZ1xoREUPXzP/tvxo4yvZ8SWexduTxoO1dASTNA462fYek1wKn\nA28Evgp80/b3JB3TcMyngLfbfkzS5sD1pXGcAOxke0Y57iHADGA6sDlwo6RryjF2LduubOK1RkTE\nEDSz2fzO9vyyfDZwbFk+D6pRCrAXcL6k7n3Glu+vBw4py98HPl+WBXxW0j7AGmAK8LJezr03cK7t\n1cD9kq4GdgceA27oq9FImgXMAhjzogEfE4+IiGFqZrPpmS/d/fqJ8n094JHu0cgg9gc4ApgE7Gb7\nGUl3ARsNsa4n+nrD9hxgDsDYydsmHzsioibNfEDgFZL2LMszgV80vmn7MWClpMMAyucs08vb84F3\nluUjGnabADxQGs1+wFZl/ePApg3bXQscLmmMpEnAPsANTbquiIgYoWY2mxXAMZJuBTYDvtnLNkcA\nR0laDCwHuj/w/0jZdynVrbJu5wBdZf17gdsAbD8IzC8PBJwKXAgsARYD/wl80vbvm3htERExArJH\nfvdI0lTgEts7jfhgLdLV1eVMVxMRMTSSFtruGmi7zCAQERG1a8oDArbvAjp2VBMREfXKyCYiImqX\nZhMREbVLs4mIiNql2URERO3SbCIionaZdr9oRZ5Nf5J1ExHrkoxsIiKidv02G0mnNE75L2m2pOMk\nfULSjZKWSPp0eW9qybI5U9JySZdL2ri8N0PS9WX7CyVtVtZfJenLkhaUfXeX9CNJd/TItfl4mZpm\nmaSPNpxvWcM2x0maXZaPlXRLOd8Pm/jrFRERwzDQyOY84O8aXv8d8AdgW2APqgyZ3UoEAGX9N2zv\nCDzC2tiA7wHH294ZWAr8c8Mx/1ymOjgD+DFwDNUPiL5f0ksk7QZ8AHgt8Drgg5J2GaDuE4BdyvmO\nHmDbiIioWb/NxvZNwEslbVFmaH4YmAYcANwELAK2p2oyACtt31yWFwJTJU0AJtq+uqz/LtWszN0u\nLt+XAstt32f7aeBOYEuqrJoLbT9hexXwI+ANA1zXEuAcSe8Gnu1rI0mzyqhqweonHx3gkBERMVyD\n+czmfOBQ4HCqkY6Az9meUb62sf2dsu3TDfutZnAPIHTvs6bH/msG2P/ZHvU35twcCHyDKqXzRkm9\nHsf2HNtdtrvGjJswiFIjImI4BtNszqPKmjmUqvFcBhxZkjeRNEXSS/va2fajwMOSukcj7wGu7mv7\nXlwLvE3SOEmbAG8v6+6nGnW9RNJY4KBSz3rAlravBI6nysQZP4TzRUREkw048rC9XNKmwD227wPu\nk/Qa4LoS77wKeDfVSKYv7wPOkDSO6vbYBwZboO1FkuayNgzt2+X2HpI+U9bfQ8m6AcYAZ5fbdwJO\ns/3IYM8XERHN15Q8m3VB8mwiIoYueTYREdE20mwiIqJ2aTYREVG7NJuIiKhdmk1ERNQuzSYiImqX\niIGi3SIGRioRBRHRTmod2Uj6qaSJfby3qs5zR0RE+6h1ZGP7zT3XqZp2QCM5rqT1bfc5wWZERLSX\npo1sJF0kaWHJsplV1t0lafOSPbNC0veAZVSzOVOybJZLmidpUlnXX/bNVyQtAD4iaa6k0yT9UtKd\nkg5tqOV5eTsREdE6zbyNdqTt3YAu4FhJL+nx/rbA6bZ3tP1bYBNgQcm+uZq1GTf9Zd9sWGZp/lJ5\nPZkqguAg4BQASQfQd97OcyRiICJidDSz2RwraTFwPdXIZdse7//W9vUNr9dQzSgNcDaw9yCyb87j\nuS6yvcb2LcDLyroD6Dtv5zkSMRARMTqa8pmNpH2B/YE9bT8p6Sqemy8D8MQAhxnMjKA9j9GYf6OG\n75+z/a1BHC8iIkZBs0Y2E4CHS6PZniq+eTDn7v6cZSbwiyZk38AQ83YiIqJ+zXoa7VLgaEm3Aiuo\nbqUN5AlgD0knAQ9QJYHCCLJvAGxf3kfezgP97TdtygQW5GdTIiJqkTybInk2ERFDlzybiIhoG2k2\nERFRuzSbiIioXZpNRETULs0mIiJql2YTERG169g8mxJdMNP26eX1FsBptg/tf8/erWt5Ni9EyfCJ\naF+dPLKZCHyo+4Xte4fbaCIiol51h6f1FjvwAUm3S7pB0pmSvl7Wz+0RE7CqfB9fIggWSVoq6eCy\nySnA1pJulnRqiTFYVvYZI+mLkpaVmIG/r/M6IyKif3XfRjvS9kOSNgZulPQT4NPAbsCjwJVUszP3\n5yng7bYfk7Q5cL2ki4ETgJ1szwCQNLVhn1nAVGCG7WclvbiJ1xQREUNUd7M5VtLby/KWVBNrXmX7\nDwCSzgO2G+AYAj5bMmnWAFNYGyfQl/2BM7rTPG0/1OuBq9HWLIAxL5o08NVERMSw1HYbrUfswHSq\nEcxt/ezybHc9ktYDNizrjwAmAbuVUcz9PD++YFiSZxMRMTrq/Mymt9iBjYG/kvQSSRsAhzVsfxfV\n7TWAtwIbNBznAdvPSNoP2KqsfxzYtI9zXwH8b0nrA+Q2WkREa9XZbC4F1i+xA6dQxQ7cB8wGrgPm\nA7c2bH8mVSNaDOzJ2qC0c4AuSUuB91JGR7YfBOaXhwBO7XHubwP/BSwpx5vZ/MuLiIjBamnEgKT3\nA122P9yyIopEDEREDF0iBiIiom20dAYB23OBua2sISIi6peRTURE1C7NJiIiapdmExERtUuziYiI\n2nVsxECzJWIgElEQUZ+OGdlIOlbSrZIelnRCq+uJiIjB66SRzYeA/W3f3epCIiJiaDpiZCPpDOBV\nwM8kfaxHBs5pkn4p6c7uPBxJkyVdU7Julkl6Qyvrj4h4oeuIZmP7aOBeYD/g4R5vTwb2Bg6imoMN\nqrnQLiuzRE8Hbu7tuJJmSVogacHqJx+tpfaIiOis22h9ucj2GuAWSd05NzcCZ5WZpS+y3WuzsT0H\nmAMwdvK2rZskLiJiHdcRI5sBPN2wLADb1wD7APcAcyW9txWFRUREZV1oNs8jaSvgfttnUsUN7Nri\nkiIiXtDWhdtovdkX+ISkZ4BVVDk4/Zo2ZQIL8nMWERG1aGmeTTtJnk1ExNAlzyYiItpGmk1ERNQu\nzSYiImqXZhMREbVLs4mIiNql2URERO066udsJE0EZto+fYDtfml7L0lTgUts7zTQsZNnE71Jxk1E\nc3TayGYiVdRAv2zvNQq1RETEIHXUyIZqVuetJd0MXAnsDGwGbACcZPvHAJJW2R7fujIjIqJRpzWb\nE4CdbM+QtD4wzvZjkjYHrpd0sTMlQkRE2+m0ZtNIwGcl7QOsAaYALwN+P+gDSLOAWQBjXjSpjhoj\nIoLO+8ym0RHAJGC3EpJ2P7DRUA5ge47tLttdY8ZNqKPGiIig85rN48CmZXkC8IDtZyTtB2zVurIi\nIqI/HXUbzfaDkuZLWkaVxrm9pKXAAuC21lYXERF9ScRAkYiBiIihS8RARES0jTSbiIioXZpNRETU\nLs0mIiJql2YTERG1S7OJiIjaddTP2dQpEQPRLhJrEOuiIY1sJE0tP1A5bJL2lXRJL+tnSzpuJMeO\niIj2lNtoERFRu+E0m/UlnSPpVkkXSBon6Z8k3ShpmaQ5kgQgaRtJP5e0WNIiSVs3HkjS7pJualg/\nXdJ1ku6Q9MGyjSSdWo69VNLhZf2+kq4qNdxWauo+726Srpa0UNJlkiYP/5coIiJGajjN5tXA6bZf\nAzxGlZz5ddu7l/jljYGDyrbnAN+wPR3YC7iv+yCS9gLOAA62/ZuyemfgjcCewD9J2gJ4BzADmA7s\nD5za0Dx2AT4K7AC8Cni9pA2ArwGH2t4NOAv4f71diKRZkhZIWrD6yUeH8UsRERGDMZwHBH5ne35Z\nPhs4Flgp6ZPAOODFwHJJVwFTbF8IYPspgDL4eA0wBzjA9r0Nx/6x7T8Bf5J0JbAHsDdwru3VwP2S\nrgZ2p2p0N9i+uxz3ZmAq8AiwE3BFOdcYGppcI9tzSh2MnbxtJomLiKjJcJpNz3+UDZwOdNn+naTZ\nDJwrc1/ZZhegsdn0duz+PN2wvJrqegQst73nAPtGRMQoGc5ttFdI6v6HfCbwi7L8R0njgUMBbD8O\n3C3pbQCSxkoaV7Z9BDgQ+JykfRuOfbCkjSS9BNiXKkbgWuBwSWMkTQL2AW7op74VwKTuGiVtIGnH\nYVxnREQ0yXBGNiuAYySdBdwCfBPYDFhGFcl8Y8O27wG+JekzwDPAYd1v2L5f0kHAzyQdWVYvAa4E\nNgf+xfa9ki6k+gxnMdVI55O2fy9p+96Ks/1nSYcCp0maUK7xK8Dy/i5q2pQJLMjPN0RE1CJ5NkXy\nbCIihi55NhER0TbSbCIionZpNhERUbs0m4iIqF2aTURE1C7NJiIiatfxeTaS3grsYPuUMnvBKttf\nLNPlHGd7UM8zJ88m1hXJw4l21PHNxvbFwMWtriMiIvrW1rfRSljbbZLmSrq9xAjsL2l+iSHYQ9L7\nJX29n2OsV/Y/eTRrj4iItdq62RTbAF8Cti9fM6lmgj4O+McB9l2fKubgDtsn1VlkRET0rROazUrb\nS22voZrfbJ6rOXaWUkUK9OdbwDLbybOJiGihTmg2jTECaxper2Hgz5x+CewnqdfIA9tzbHfZ7hoz\nbsLIK42IiF51QrMZie8APwX+TVLHPwwREdGp1vVmg+1/BW4Cvi9pnb/eiIh2lIiBIhEDERFDl4iB\niIhoG2k2ERFRuzSbiIioXZpNRETULs0mIiJql2YTERG1yw86FokYiHi+xBVEszR9ZCNpoqQPDXPf\nqZJmNrzud0bnQRxvX0mXDHf/iIhojjpuo00EhtVsqCbWnDnQRhER0VnqaDanAFtLulnSqeVrmaSl\nkg4HUOV568u+byj7fqys20LSpSW/5gvdJ5F0gKTrJC2SdL6k8WX9m0oGziLgHTVcX0REDFEdzeYE\n4De2ZwDXAzOA6cD+wKmSJlM1gd7WnwBca3uG7S+X480ADgemAYdL2lLS5sBJwP62dwUWAB8vszuf\nCbwF2A34H/0VmoiBiIjRUfcDAnsD59peDdwv6Wpg937WP9bLMebZfhRA0i3AVlS36nYA5ksC2BC4\njipcbaXtO8r2ZwOz+irO9hxgDsDYydtmkriIiJp0wtNojXk2q6lqFnCF7Xc1bihpxmgWFhERg1PH\nbbTHgU3L8rVUt77GSJoE7APc0M/6xn37cz3weknbAEjaRNJ2wG3AVElbl+3e1dcBIiJi9DR9ZGP7\nQUnzJS0DfgYsARYDBj5p+/eSLgT27GX9g8BqSYuBucDDfZzjD5LeD5wraWxZfZLt2yXNAn4i6Umq\npjaY5sW0KRNYkJ8piIioRfJsiuTZREQMXfJsIiKibaTZRERE7dJsIiKidmk2ERFRuzSbiIioXZpN\nRETUbkQ/ZyNpKnCJ7Z2aUs3a4+4L/Nn2L8vrueU8FzTzPI2SZxMxsOTbxHDVPrKRNGYYu+0L7NXk\nUiIiokWa0WzWl3SOpFslXSBpnKS7JH2+TPN/mKStS0zAQknXStoeQNJbJP1K0k2Sfi7pZWW0dDTw\nsRI18IZynn0k/VLSnZIO7T65pE9IulHSEkmfLus2kfQTSYtLjMHhREREyzRjuppXA0fZni/pLNYG\npz1Ypv9H0jzgaNt3SHotcDrwRuAXwOtsW9L/opq25v9KOgNYZfuLZf+jgMlUs0VvD1wMXCDpAGBb\nYA+qyTkvlrQPMAm41/aBZf8JTbjOiIgYpmY0m9/Znl+WzwaOLcvnAZRQs72A80scAED3fGYvB84r\nWTYbAiv7Oc9FttcAt0h6WVl3QPm6qbweT9V8rgW+JOnzVJ/1XNvbAcs8arMAxrxo0uCuNiIihqwZ\nzabn5Grdr58o39cDHilhaj19DfhX2xeXhwJm93OexqgBNXz/nO1v9dxY0q7Am4GTJc2z/ZnnFZ48\nm4iIUdGMz2xeIWnPsjyT6tbYX9h+DFgp6TD4SyT09PL2BOCesvy+ht0GGzVwGXBkQyT0FEkvlbQF\n8KTts4FTgV2HcV0REdEkzWg2K4BjJN0KbAZ8s5dtjgCOKtEBy4GDy/rZVLfXFgJ/bNj+P4C393hA\n4HlsXw78ALhO0lLgAqomNQ24QdLNwD8DJ4/g+iIiYoQSMVAkYiAiYugSMRAREW0jzSYiImqXZhMR\nEbVLs4mIiNql2URERO3SbCIionZpNhERUbtmTFdTG0mrbI8fjXMlzyYiminZP8+VkU1ERNSuY5pN\nb7k1Zf2nJK2Q9AtJ50o6rqw/VtItZfsftq7yiIho69to3frJrfkTcAgwHdgAWAQsLLudALzS9tOS\nJvZx3EQMRESMgo5oNvSdW7Mp8GPbTwFPSfqPhn2WAOdIugi4qLeDJmIgImJ0dMpttO7cmhnlaxvb\n3xlgnwOBb1DFC9woqVMaa0TEOqdTmk2vuTXAfOAtkjYq7x1U3l8P2NL2lcDxVLk5o/JUW0REPF9H\n/G/f9uWSXkOVWwOwCni37RslXUx1y+x+YCnwKDAGOFvSBKpR0Wm2H+nvHNOmTGBBHlWMiKhFWzeb\nxp+xsf1V4Ku9bPZF27MljQOuARbafgbYe5TKjIiIAbR1sxmkOZJ2ADYCvmt7UasLioiI5+r4ZmN7\nZqtriIiI/nXKAwIREdHB0mwiIqJ2aTYREVG7NJuIiKhdxz8g0CyJGIiIur2QYwcysomIiNq1XbOR\n9G5JN0i6WdK3JI2RdJSk28v6MyV9vWy7taTrJS2VdLKkVWX9ZEnXlGMsk/SG1l5VRMQLW1s1mzIl\nzeHA623PAFYDRwCfAl4HvB7YvmGXrwJftT0NuLth/UzgsnKM6cDNo1B+RET0od0+s/lrYDeqWZoB\nNgb2Aq62/RCApPOB7cr2ewJvK8s/AL5Ylm8EzpK0AXCR7V6bTfJsIiJGR1uNbKgmzfxuQ5TAq4HZ\nQz2I7WuAfYB7gLmS3tvHdnNsd9nuGjNuwkjqjoiIfrRbs5kHHFriA5D0YqrAtL+StFnJpDmkYfvr\nG16/s3ulpK2A+22fCXybKtMmIiJapK1uo9m+RdJJwOUlk+YZ4Bjgs8ANwEPAbVQxAgAfpYoSOBG4\ntGH9vsAnJD1DFUfQ68gmIiJGh+z2T0OWNN72qjKyuRA4y/aFJVbgT7Yt6Z3Au2wfPJxzdHV1ecGC\nBc0sOyJinSdpoe2ugbZrq5FNP2ZL2p8qRuBy4KKyfjfg66qeJngEOLJF9UVERD86otnYPq6P9ddS\nPdocERFtrN0eEIiIiHVQmk1ERNQuzSYiImqXZhMREbVLs4mIiNo17Wk0SccC/wdYZPuIIew3FdjL\n9g/K6/cDXbY/3KzaBiN5NhHRjtaVDJxmjmw+BPzNUBpNMZVqluamkDSmWceKiIjmaEqzkXQG8Crg\nZ5JOlHRWyZ65SdLBZZupkq6VtKh87VV2PwV4Q8me+VhZt4WkSyXdIekLDec5QNJ1Zf/zJY0v6++S\n9HlJi4DDJB0r6RZJSyT9sBnXGBERw9eU22i2j5b0JmA/4OPAf9o+UtJE4AZJPwceoBr5PCVpW+Bc\noAs4ATjO9kHwl9toM4BdgKeBFZK+BvwJOAnY3/YTko4v5/pMKeNB27uWY9wLvNL206WGiIhooTpm\nEDgAeKuk7p/63wh4BXAv1dQy3aFo2/WxP8A8248CSLoF2AqYCOwAzC9ZNxsC1zXsc17D8hLgHEkX\nsXZqm+dJnk1ExOioo9kIOMT2iueslGYD91NNL7Me8FQ/x3i6YXk1VZ0CrrD9rj72eaJh+UCqPJu3\nACdKmmb72Z472J4DzAEYO3nb9p+RNCKiQ9Xx6PNlwN+XyTGRtEtZPwG4z/Ya4D1A9wf5jwObDuK4\n1wOvl7RNOe4mkp43OirRBFvavhI4vpx3/AiuJyIiRqiOkc2/AF8BlpR/+FcCBwGnA/9eUjMvZe1I\nZAmwWtJiYC7wcG8Htf2H8nnOuZLGltUnAbf32HQMVcbNBKrR0Gm2Hxmo6GlTJrBgHXnEMCKi3XRE\nns1oSJ5NRMTQDTbPJjMIRERE7dJsIiKidmk2ERFRuzSbiIioXZpNRETULs0mIiJqV8fP2TRViSC4\nxPZOg9z+aOBJ298bynkSMRARL0SjFWHQ9s1mqGyf0dt6Sev3NmVNRETUr1Nuo42RdKak5ZIul7Sx\npA9KulHSYkn/LmkcVHOwdU8CKukqSV+RtAD4SEuvICLiBaxTms22wDds7wg8AhwC/Mj27ranA7cC\nR/Wx74a2u2x/aZRqjYiIHjrlNtpK2zeX5YVU6Z47STqZKnpgPNUEoL05r4/1iRiIiBglnTKy6S1y\nYC7wYdvTgE9T5eb05ok+1mN7Thn1dI0ZN6FZtUZERA+d0mx6sylwn6QNgCNaXUxERPStU26j9eZT\nwK+AP5Tvg8nEiYiIFkjEQJGIgYiIoUvEQEREtI00m4iIqF2aTURE1C6f2RSSHgdWtLqOEdgc+GOr\nixiB1N96nX4Nqb81trI94A8qdvLTaM22YjAfcrUrSQtSf+t0ev3Q+deQ+ttbbqNFRETt0mwiIqJ2\naTZrzWl1ASOU+lur0+uHzr+G1N/G8oBARETULiObiIio3TrfbCS9SdIKSb+WdEIv74+VdF55/1cl\nhrr7vX8o61dI+tvRrLtHjcO6Bkl/I2mhpKXl+xtHu/ZSx7B/D8r7r5C0qjsUb7SN8M/QzpKuK8F/\nSyX1NTt5bUbw52cDSd8tdd8q6R9Gu/ZSx0D17yNpkaRnJR3a4733SbqjfL1v9Kp+Tg3Dql/SjIY/\nO0skHT66lTeZ7XX2CxgD/AZ4FbAhsBjYocc2HwLOKMvvBM4ryzuU7ccCryzHGdNh17ALsEVZ3gm4\np5Pqb3j/AuB84LhOqp/qRwuWANPL65eM9p+hEdY/E/hhWR4H3AVMbcP6pwI7A98DDm1Y/2LgzvJ9\ns7K8WQfVvx2wbVneArgPmDia9Tfza10f2ewB/Nr2nbb/DPwQOLjHNgcD3y3LFwB/LUll/Q9tP217\nJfDrcrzRNuxrsH2T7XvL+uXAxpLGjkrVa43k9wBJbwNWUtXfCiOp/wBgie3FALYftL16lOruNpL6\nDWwiaX1gY+DPwGOjU/ZfDFi/7btsLwHW9Nj3b4ErbD9k+2HgCuBNo1F0g2HXb/t223eU5XuBB4CO\nTXlc15vNFOB3Da/vLut63cb2s8CjVP8DHcy+o2Ek19DoEGCR7acZXcOuX9J44HiqcLxWGcmv/3aA\nJV1WbpN8chTq7Wkk9V9AFT54H/BfwBdtP1R3wX3VVgzl72E7/B1uSg2S9qAaGf2mSXWNuswg8AIg\naUfg81T/0+4ks4Ev215VBjqdZn1gb2B34ElgXpmOfV5ryxq0PaiScbegug11raSf276ztWW9sEia\nDHwfeJ/tnqO3jrGuj2zuAbZseP3ysq7XbcrtggnAg4PcdzSM5BqQ9HLgQuC9tlvxv6KR1P9a4AuS\n7gI+CvyjpA/XXXBftRVDqf9u4Brbf7T9JPBTYNfaK+6jtmIo9c8ELrX9jO0HgPnAaE+nMpK/h+3w\nd3hENUh6EfAT4ETb1ze5ttHV6g+N6vyi+p/lnVQf8Hd/OLdjj22O4bkfjv5bWd6R5z4gcCeteUBg\nJNcwsWz/jk78PeixzWxa84DASH79NwMWUX24vj7wc+DADqr/eOD/l+VNgFuAndut/oZt5/L8BwRW\nlt+Hzcryizuo/g2BecBHR7Pm2n4tWl3AKPxmvxm4nepe54ll3WeAt5bljaiedPo1cAPwqoZ9Tyz7\nrQD+Z6ddA3AS1T33mxu+Xtop9fc4xmxa0Gya8Gfo3VQPNywDvtBJ9QPjy/rlVI3mE21a/+5Uo8gn\nqEZkyxv2PbJc16+BD3RS/eXPzjM9/v7OaMU1NOMrMwhERETt1vXPbCIiog2k2URERO3SbCIionZp\nNhERUbs0m4iIqF2aTURE1C7NJiIiapdmExERtftvJjXgwZovDWYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfHfcPeMS-sA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate dummy columns\n",
        "def generate_dummies(df, dummy_column):\n",
        "    dummies = pd.get_dummies(df[dummy_column], prefix=dummy_column)\n",
        "    df = pd.concat([df, dummies], axis=1)\n",
        "    return df\n",
        "  \n",
        "X = generate_dummies(X, \"legs\")\n",
        "\n",
        "del X[\"legs\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmbII7atTj8I",
        "colab_type": "code",
        "outputId": "0b0ac263-b20a-4669-b8f5-d20087884bcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hair</th>\n",
              "      <th>feathers</th>\n",
              "      <th>eggs</th>\n",
              "      <th>milk</th>\n",
              "      <th>airborne</th>\n",
              "      <th>aquatic</th>\n",
              "      <th>predator</th>\n",
              "      <th>toothed</th>\n",
              "      <th>backbone</th>\n",
              "      <th>breathes</th>\n",
              "      <th>venomous</th>\n",
              "      <th>fins</th>\n",
              "      <th>tail</th>\n",
              "      <th>legs_0</th>\n",
              "      <th>legs_2</th>\n",
              "      <th>legs_4</th>\n",
              "      <th>legs_5</th>\n",
              "      <th>legs_6</th>\n",
              "      <th>legs_8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   hair  feathers  eggs  milk  airborne  ...  legs_2  legs_4  legs_5  legs_6  legs_8\n",
              "0     1         0     0     1         0  ...       0       1       0       0       0\n",
              "1     1         0     0     1         0  ...       0       1       0       0       0\n",
              "2     0         0     1     0         0  ...       0       0       0       0       0\n",
              "3     1         0     0     1         0  ...       0       1       0       0       0\n",
              "4     1         0     0     1         0  ...       0       1       0       0       0\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSSpBjr0f3Hc",
        "colab_type": "code",
        "outputId": "19a880a1-506e-478d-8e9c-7d1ea0850cad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "y.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1\n",
              "1    1\n",
              "2    4\n",
              "3    1\n",
              "4    1\n",
              "5    1\n",
              "6    1\n",
              "7    4\n",
              "8    4\n",
              "9    1\n",
              "Name: class_type, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXGsESq2fKAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change the range of target variables from [1,7] to [0,6]\n",
        "for c, animal_class in enumerate(y):\n",
        "  y[c] = animal_class-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yBon7U0fh4d",
        "colab_type": "code",
        "outputId": "58dc17e7-8a6c-435c-9be3-645bfbc12b78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "y.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    3\n",
              "3    0\n",
              "4    0\n",
              "5    0\n",
              "6    0\n",
              "7    3\n",
              "8    3\n",
              "9    0\n",
              "Name: class_type, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gitMaP9Ops22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dimension = X.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQE6fyBdUEM1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NB_EPOCHS = 300  # num of epochs to test for\n",
        "BATCH_SIZE = dimension"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjnYBvsOVMQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the dataset into train and testset\n",
        "TESTSIZE = 0.3\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = TESTSIZE, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z80zjYLfT77S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ensure that fieldnames aren't included\n",
        "X_train = X_train.values\n",
        "y_train = y_train.values\n",
        "X_test  = X_test.values\n",
        "y_test  = y_test.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trJArjIIUYFN",
        "colab_type": "code",
        "outputId": "779b1035-d7de-433c-c67b-defe729b9bf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# Create our model\n",
        "model = tf.keras.Sequential()\n",
        "model.add(layers.Dense(dimension+2, input_dim = dimension, activation='elu'))\n",
        "model.add(layers.Dense(dimension+2, input_dim = dimension, activation='elu'))\n",
        "model.add(layers.Dense(7,           input_dim = dimension, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_21 (Dense)             (None, 21)                420       \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 21)                462       \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 7)                 154       \n",
            "=================================================================\n",
            "Total params: 1,036\n",
            "Trainable params: 1,036\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bcDWa_vdavJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', \n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtU1TccNVeRP",
        "colab_type": "code",
        "outputId": "ebe25b72-5423-4a0f-87fb-4b90a9cfccdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#set early stopping monitor so the model stops training when it won't improve anymore\n",
        "early_stopping_monitor = EarlyStopping(patience=10)\n",
        "\n",
        "# Train the model, store the results for plotting\n",
        "print('Training...')\n",
        "history = model.fit(X_train,\n",
        "                    y_train,\n",
        "                    validation_split = 0.2,\n",
        "                    #validation_data = (X_test, y_test),\n",
        "                    nb_epoch        = NB_EPOCHS,\n",
        "                    batch_size      = BATCH_SIZE,\n",
        "                    callbacks       = [early_stopping_monitor],\n",
        "                    verbose         = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0714 18:15:14.997638 140177027491712 training.py:593] The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Train on 56 samples, validate on 14 samples\n",
            "Epoch 1/300\n",
            "56/56 [==============================] - 0s 4ms/sample - loss: 1.9193 - acc: 0.0714 - val_loss: 1.9443 - val_acc: 0.0714\n",
            "Epoch 2/300\n",
            "56/56 [==============================] - 0s 255us/sample - loss: 1.8778 - acc: 0.1250 - val_loss: 1.8973 - val_acc: 0.3571\n",
            "Epoch 3/300\n",
            "56/56 [==============================] - 0s 228us/sample - loss: 1.8393 - acc: 0.2500 - val_loss: 1.8511 - val_acc: 0.3571\n",
            "Epoch 4/300\n",
            "56/56 [==============================] - 0s 205us/sample - loss: 1.8028 - acc: 0.2500 - val_loss: 1.8076 - val_acc: 0.3571\n",
            "Epoch 5/300\n",
            "56/56 [==============================] - 0s 219us/sample - loss: 1.7677 - acc: 0.3393 - val_loss: 1.7664 - val_acc: 0.5000\n",
            "Epoch 6/300\n",
            "56/56 [==============================] - 0s 222us/sample - loss: 1.7353 - acc: 0.3929 - val_loss: 1.7278 - val_acc: 0.5714\n",
            "Epoch 7/300\n",
            "56/56 [==============================] - 0s 226us/sample - loss: 1.7053 - acc: 0.4107 - val_loss: 1.6898 - val_acc: 0.5714\n",
            "Epoch 8/300\n",
            "56/56 [==============================] - 0s 186us/sample - loss: 1.6736 - acc: 0.4464 - val_loss: 1.6535 - val_acc: 0.6429\n",
            "Epoch 9/300\n",
            "56/56 [==============================] - 0s 404us/sample - loss: 1.6449 - acc: 0.5714 - val_loss: 1.6179 - val_acc: 0.6429\n",
            "Epoch 10/300\n",
            "56/56 [==============================] - 0s 252us/sample - loss: 1.6157 - acc: 0.5714 - val_loss: 1.5836 - val_acc: 0.5714\n",
            "Epoch 11/300\n",
            "56/56 [==============================] - 0s 281us/sample - loss: 1.5866 - acc: 0.5714 - val_loss: 1.5502 - val_acc: 0.5714\n",
            "Epoch 12/300\n",
            "56/56 [==============================] - 0s 242us/sample - loss: 1.5605 - acc: 0.5714 - val_loss: 1.5170 - val_acc: 0.5714\n",
            "Epoch 13/300\n",
            "56/56 [==============================] - 0s 299us/sample - loss: 1.5324 - acc: 0.5714 - val_loss: 1.4847 - val_acc: 0.5714\n",
            "Epoch 14/300\n",
            "56/56 [==============================] - 0s 199us/sample - loss: 1.5074 - acc: 0.5714 - val_loss: 1.4517 - val_acc: 0.5714\n",
            "Epoch 15/300\n",
            "56/56 [==============================] - 0s 205us/sample - loss: 1.4793 - acc: 0.5714 - val_loss: 1.4203 - val_acc: 0.5714\n",
            "Epoch 16/300\n",
            "56/56 [==============================] - 0s 173us/sample - loss: 1.4532 - acc: 0.5714 - val_loss: 1.3884 - val_acc: 0.5714\n",
            "Epoch 17/300\n",
            "56/56 [==============================] - 0s 304us/sample - loss: 1.4276 - acc: 0.5893 - val_loss: 1.3566 - val_acc: 0.5714\n",
            "Epoch 18/300\n",
            "56/56 [==============================] - 0s 283us/sample - loss: 1.4008 - acc: 0.5893 - val_loss: 1.3248 - val_acc: 0.5714\n",
            "Epoch 19/300\n",
            "56/56 [==============================] - 0s 234us/sample - loss: 1.3744 - acc: 0.6071 - val_loss: 1.2929 - val_acc: 0.5714\n",
            "Epoch 20/300\n",
            "56/56 [==============================] - 0s 333us/sample - loss: 1.3483 - acc: 0.6071 - val_loss: 1.2613 - val_acc: 0.7143\n",
            "Epoch 21/300\n",
            "56/56 [==============================] - 0s 273us/sample - loss: 1.3225 - acc: 0.6071 - val_loss: 1.2296 - val_acc: 0.7143\n",
            "Epoch 22/300\n",
            "56/56 [==============================] - 0s 236us/sample - loss: 1.2960 - acc: 0.6071 - val_loss: 1.1987 - val_acc: 0.7143\n",
            "Epoch 23/300\n",
            "56/56 [==============================] - 0s 298us/sample - loss: 1.2692 - acc: 0.6071 - val_loss: 1.1682 - val_acc: 0.7143\n",
            "Epoch 24/300\n",
            "56/56 [==============================] - 0s 286us/sample - loss: 1.2443 - acc: 0.6429 - val_loss: 1.1368 - val_acc: 0.7143\n",
            "Epoch 25/300\n",
            "56/56 [==============================] - 0s 348us/sample - loss: 1.2176 - acc: 0.6429 - val_loss: 1.1062 - val_acc: 0.7143\n",
            "Epoch 26/300\n",
            "56/56 [==============================] - 0s 292us/sample - loss: 1.1928 - acc: 0.6429 - val_loss: 1.0753 - val_acc: 0.7143\n",
            "Epoch 27/300\n",
            "56/56 [==============================] - 0s 221us/sample - loss: 1.1675 - acc: 0.6429 - val_loss: 1.0449 - val_acc: 0.7143\n",
            "Epoch 28/300\n",
            "56/56 [==============================] - 0s 249us/sample - loss: 1.1428 - acc: 0.6429 - val_loss: 1.0151 - val_acc: 0.7143\n",
            "Epoch 29/300\n",
            "56/56 [==============================] - 0s 290us/sample - loss: 1.1178 - acc: 0.6429 - val_loss: 0.9866 - val_acc: 0.7143\n",
            "Epoch 30/300\n",
            "56/56 [==============================] - 0s 307us/sample - loss: 1.0942 - acc: 0.6429 - val_loss: 0.9584 - val_acc: 0.7143\n",
            "Epoch 31/300\n",
            "56/56 [==============================] - 0s 369us/sample - loss: 1.0703 - acc: 0.6786 - val_loss: 0.9310 - val_acc: 0.7143\n",
            "Epoch 32/300\n",
            "56/56 [==============================] - 0s 249us/sample - loss: 1.0465 - acc: 0.7143 - val_loss: 0.9051 - val_acc: 0.7143\n",
            "Epoch 33/300\n",
            "56/56 [==============================] - 0s 259us/sample - loss: 1.0236 - acc: 0.7321 - val_loss: 0.8797 - val_acc: 0.7143\n",
            "Epoch 34/300\n",
            "56/56 [==============================] - 0s 295us/sample - loss: 1.0016 - acc: 0.7321 - val_loss: 0.8548 - val_acc: 0.7143\n",
            "Epoch 35/300\n",
            "56/56 [==============================] - 0s 276us/sample - loss: 0.9793 - acc: 0.7321 - val_loss: 0.8309 - val_acc: 0.7143\n",
            "Epoch 36/300\n",
            "56/56 [==============================] - 0s 330us/sample - loss: 0.9577 - acc: 0.7321 - val_loss: 0.8076 - val_acc: 0.7143\n",
            "Epoch 37/300\n",
            "56/56 [==============================] - 0s 268us/sample - loss: 0.9372 - acc: 0.7321 - val_loss: 0.7846 - val_acc: 0.7143\n",
            "Epoch 38/300\n",
            "56/56 [==============================] - 0s 328us/sample - loss: 0.9165 - acc: 0.7500 - val_loss: 0.7626 - val_acc: 0.7143\n",
            "Epoch 39/300\n",
            "56/56 [==============================] - 0s 237us/sample - loss: 0.8960 - acc: 0.7500 - val_loss: 0.7416 - val_acc: 0.7143\n",
            "Epoch 40/300\n",
            "56/56 [==============================] - 0s 220us/sample - loss: 0.8760 - acc: 0.7500 - val_loss: 0.7206 - val_acc: 0.7143\n",
            "Epoch 41/300\n",
            "56/56 [==============================] - 0s 287us/sample - loss: 0.8568 - acc: 0.7500 - val_loss: 0.7005 - val_acc: 0.7143\n",
            "Epoch 42/300\n",
            "56/56 [==============================] - 0s 291us/sample - loss: 0.8377 - acc: 0.7500 - val_loss: 0.6811 - val_acc: 0.7143\n",
            "Epoch 43/300\n",
            "56/56 [==============================] - 0s 250us/sample - loss: 0.8194 - acc: 0.7500 - val_loss: 0.6619 - val_acc: 0.7143\n",
            "Epoch 44/300\n",
            "56/56 [==============================] - 0s 323us/sample - loss: 0.8010 - acc: 0.7500 - val_loss: 0.6438 - val_acc: 0.7143\n",
            "Epoch 45/300\n",
            "56/56 [==============================] - 0s 296us/sample - loss: 0.7825 - acc: 0.7500 - val_loss: 0.6265 - val_acc: 0.7143\n",
            "Epoch 46/300\n",
            "56/56 [==============================] - 0s 312us/sample - loss: 0.7657 - acc: 0.7500 - val_loss: 0.6092 - val_acc: 0.7143\n",
            "Epoch 47/300\n",
            "56/56 [==============================] - 0s 293us/sample - loss: 0.7486 - acc: 0.7500 - val_loss: 0.5932 - val_acc: 0.7143\n",
            "Epoch 48/300\n",
            "56/56 [==============================] - 0s 295us/sample - loss: 0.7326 - acc: 0.7500 - val_loss: 0.5778 - val_acc: 0.7143\n",
            "Epoch 49/300\n",
            "56/56 [==============================] - 0s 302us/sample - loss: 0.7164 - acc: 0.7500 - val_loss: 0.5627 - val_acc: 0.7143\n",
            "Epoch 50/300\n",
            "56/56 [==============================] - 0s 276us/sample - loss: 0.7003 - acc: 0.7500 - val_loss: 0.5485 - val_acc: 0.7143\n",
            "Epoch 51/300\n",
            "56/56 [==============================] - 0s 297us/sample - loss: 0.6852 - acc: 0.7500 - val_loss: 0.5336 - val_acc: 0.7143\n",
            "Epoch 52/300\n",
            "56/56 [==============================] - 0s 277us/sample - loss: 0.6710 - acc: 0.7500 - val_loss: 0.5206 - val_acc: 0.7857\n",
            "Epoch 53/300\n",
            "56/56 [==============================] - 0s 245us/sample - loss: 0.6557 - acc: 0.7500 - val_loss: 0.5074 - val_acc: 0.7857\n",
            "Epoch 54/300\n",
            "56/56 [==============================] - 0s 257us/sample - loss: 0.6417 - acc: 0.7500 - val_loss: 0.4951 - val_acc: 0.7857\n",
            "Epoch 55/300\n",
            "56/56 [==============================] - 0s 233us/sample - loss: 0.6281 - acc: 0.7500 - val_loss: 0.4834 - val_acc: 0.7857\n",
            "Epoch 56/300\n",
            "56/56 [==============================] - 0s 287us/sample - loss: 0.6140 - acc: 0.7321 - val_loss: 0.4713 - val_acc: 0.7857\n",
            "Epoch 57/300\n",
            "56/56 [==============================] - 0s 307us/sample - loss: 0.6008 - acc: 0.7321 - val_loss: 0.4598 - val_acc: 0.8571\n",
            "Epoch 58/300\n",
            "56/56 [==============================] - 0s 270us/sample - loss: 0.5875 - acc: 0.7321 - val_loss: 0.4492 - val_acc: 0.8571\n",
            "Epoch 59/300\n",
            "56/56 [==============================] - 0s 292us/sample - loss: 0.5743 - acc: 0.7321 - val_loss: 0.4387 - val_acc: 0.8571\n",
            "Epoch 60/300\n",
            "56/56 [==============================] - 0s 328us/sample - loss: 0.5616 - acc: 0.7679 - val_loss: 0.4281 - val_acc: 0.8571\n",
            "Epoch 61/300\n",
            "56/56 [==============================] - 0s 294us/sample - loss: 0.5484 - acc: 0.7679 - val_loss: 0.4175 - val_acc: 0.8571\n",
            "Epoch 62/300\n",
            "56/56 [==============================] - 0s 343us/sample - loss: 0.5354 - acc: 0.7679 - val_loss: 0.4077 - val_acc: 0.8571\n",
            "Epoch 63/300\n",
            "56/56 [==============================] - 0s 257us/sample - loss: 0.5221 - acc: 0.7679 - val_loss: 0.3978 - val_acc: 0.9286\n",
            "Epoch 64/300\n",
            "56/56 [==============================] - 0s 241us/sample - loss: 0.5090 - acc: 0.8571 - val_loss: 0.3884 - val_acc: 1.0000\n",
            "Epoch 65/300\n",
            "56/56 [==============================] - 0s 286us/sample - loss: 0.4956 - acc: 0.8750 - val_loss: 0.3781 - val_acc: 1.0000\n",
            "Epoch 66/300\n",
            "56/56 [==============================] - 0s 326us/sample - loss: 0.4829 - acc: 0.8929 - val_loss: 0.3685 - val_acc: 1.0000\n",
            "Epoch 67/300\n",
            "56/56 [==============================] - 0s 317us/sample - loss: 0.4688 - acc: 0.9107 - val_loss: 0.3583 - val_acc: 1.0000\n",
            "Epoch 68/300\n",
            "56/56 [==============================] - 0s 388us/sample - loss: 0.4556 - acc: 0.9107 - val_loss: 0.3481 - val_acc: 1.0000\n",
            "Epoch 69/300\n",
            "56/56 [==============================] - 0s 219us/sample - loss: 0.4423 - acc: 0.9107 - val_loss: 0.3378 - val_acc: 1.0000\n",
            "Epoch 70/300\n",
            "56/56 [==============================] - 0s 289us/sample - loss: 0.4284 - acc: 0.9107 - val_loss: 0.3280 - val_acc: 1.0000\n",
            "Epoch 71/300\n",
            "56/56 [==============================] - 0s 258us/sample - loss: 0.4154 - acc: 0.9107 - val_loss: 0.3181 - val_acc: 1.0000\n",
            "Epoch 72/300\n",
            "56/56 [==============================] - 0s 225us/sample - loss: 0.4014 - acc: 0.9107 - val_loss: 0.3081 - val_acc: 1.0000\n",
            "Epoch 73/300\n",
            "56/56 [==============================] - 0s 326us/sample - loss: 0.3881 - acc: 0.9107 - val_loss: 0.2980 - val_acc: 1.0000\n",
            "Epoch 74/300\n",
            "56/56 [==============================] - 0s 329us/sample - loss: 0.3757 - acc: 0.9286 - val_loss: 0.2876 - val_acc: 1.0000\n",
            "Epoch 75/300\n",
            "56/56 [==============================] - 0s 300us/sample - loss: 0.3635 - acc: 0.9286 - val_loss: 0.2788 - val_acc: 1.0000\n",
            "Epoch 76/300\n",
            "56/56 [==============================] - 0s 318us/sample - loss: 0.3501 - acc: 0.9464 - val_loss: 0.2689 - val_acc: 1.0000\n",
            "Epoch 77/300\n",
            "56/56 [==============================] - 0s 274us/sample - loss: 0.3385 - acc: 0.9464 - val_loss: 0.2610 - val_acc: 1.0000\n",
            "Epoch 78/300\n",
            "56/56 [==============================] - 0s 251us/sample - loss: 0.3264 - acc: 0.9643 - val_loss: 0.2520 - val_acc: 1.0000\n",
            "Epoch 79/300\n",
            "56/56 [==============================] - 0s 293us/sample - loss: 0.3156 - acc: 0.9643 - val_loss: 0.2429 - val_acc: 1.0000\n",
            "Epoch 80/300\n",
            "56/56 [==============================] - 0s 288us/sample - loss: 0.3044 - acc: 0.9643 - val_loss: 0.2349 - val_acc: 1.0000\n",
            "Epoch 81/300\n",
            "56/56 [==============================] - 0s 253us/sample - loss: 0.2938 - acc: 0.9643 - val_loss: 0.2279 - val_acc: 1.0000\n",
            "Epoch 82/300\n",
            "56/56 [==============================] - 0s 235us/sample - loss: 0.2831 - acc: 0.9643 - val_loss: 0.2216 - val_acc: 1.0000\n",
            "Epoch 83/300\n",
            "56/56 [==============================] - 0s 274us/sample - loss: 0.2731 - acc: 0.9643 - val_loss: 0.2154 - val_acc: 1.0000\n",
            "Epoch 84/300\n",
            "56/56 [==============================] - 0s 264us/sample - loss: 0.2642 - acc: 0.9643 - val_loss: 0.2099 - val_acc: 1.0000\n",
            "Epoch 85/300\n",
            "56/56 [==============================] - 0s 291us/sample - loss: 0.2551 - acc: 0.9643 - val_loss: 0.2031 - val_acc: 1.0000\n",
            "Epoch 86/300\n",
            "56/56 [==============================] - 0s 268us/sample - loss: 0.2468 - acc: 0.9643 - val_loss: 0.1971 - val_acc: 1.0000\n",
            "Epoch 87/300\n",
            "56/56 [==============================] - 0s 276us/sample - loss: 0.2385 - acc: 0.9643 - val_loss: 0.1919 - val_acc: 1.0000\n",
            "Epoch 88/300\n",
            "56/56 [==============================] - 0s 236us/sample - loss: 0.2309 - acc: 0.9643 - val_loss: 0.1852 - val_acc: 1.0000\n",
            "Epoch 89/300\n",
            "56/56 [==============================] - 0s 333us/sample - loss: 0.2233 - acc: 0.9643 - val_loss: 0.1799 - val_acc: 1.0000\n",
            "Epoch 90/300\n",
            "56/56 [==============================] - 0s 388us/sample - loss: 0.2164 - acc: 0.9643 - val_loss: 0.1763 - val_acc: 1.0000\n",
            "Epoch 91/300\n",
            "56/56 [==============================] - 0s 300us/sample - loss: 0.2098 - acc: 1.0000 - val_loss: 0.1727 - val_acc: 1.0000\n",
            "Epoch 92/300\n",
            "56/56 [==============================] - 0s 279us/sample - loss: 0.2028 - acc: 1.0000 - val_loss: 0.1676 - val_acc: 1.0000\n",
            "Epoch 93/300\n",
            "56/56 [==============================] - 0s 287us/sample - loss: 0.1965 - acc: 1.0000 - val_loss: 0.1636 - val_acc: 1.0000\n",
            "Epoch 94/300\n",
            "56/56 [==============================] - 0s 300us/sample - loss: 0.1902 - acc: 1.0000 - val_loss: 0.1594 - val_acc: 1.0000\n",
            "Epoch 95/300\n",
            "56/56 [==============================] - 0s 346us/sample - loss: 0.1850 - acc: 1.0000 - val_loss: 0.1561 - val_acc: 1.0000\n",
            "Epoch 96/300\n",
            "56/56 [==============================] - 0s 333us/sample - loss: 0.1789 - acc: 1.0000 - val_loss: 0.1524 - val_acc: 1.0000\n",
            "Epoch 97/300\n",
            "56/56 [==============================] - 0s 308us/sample - loss: 0.1739 - acc: 1.0000 - val_loss: 0.1493 - val_acc: 1.0000\n",
            "Epoch 98/300\n",
            "56/56 [==============================] - 0s 301us/sample - loss: 0.1685 - acc: 1.0000 - val_loss: 0.1461 - val_acc: 1.0000\n",
            "Epoch 99/300\n",
            "56/56 [==============================] - 0s 258us/sample - loss: 0.1638 - acc: 1.0000 - val_loss: 0.1440 - val_acc: 1.0000\n",
            "Epoch 100/300\n",
            "56/56 [==============================] - 0s 294us/sample - loss: 0.1592 - acc: 1.0000 - val_loss: 0.1406 - val_acc: 1.0000\n",
            "Epoch 101/300\n",
            "56/56 [==============================] - 0s 295us/sample - loss: 0.1547 - acc: 1.0000 - val_loss: 0.1383 - val_acc: 1.0000\n",
            "Epoch 102/300\n",
            "56/56 [==============================] - 0s 330us/sample - loss: 0.1501 - acc: 1.0000 - val_loss: 0.1358 - val_acc: 1.0000\n",
            "Epoch 103/300\n",
            "56/56 [==============================] - 0s 303us/sample - loss: 0.1461 - acc: 1.0000 - val_loss: 0.1337 - val_acc: 1.0000\n",
            "Epoch 104/300\n",
            "56/56 [==============================] - 0s 338us/sample - loss: 0.1422 - acc: 1.0000 - val_loss: 0.1314 - val_acc: 1.0000\n",
            "Epoch 105/300\n",
            "56/56 [==============================] - 0s 275us/sample - loss: 0.1380 - acc: 1.0000 - val_loss: 0.1289 - val_acc: 1.0000\n",
            "Epoch 106/300\n",
            "56/56 [==============================] - 0s 378us/sample - loss: 0.1346 - acc: 1.0000 - val_loss: 0.1268 - val_acc: 1.0000\n",
            "Epoch 107/300\n",
            "56/56 [==============================] - 0s 308us/sample - loss: 0.1308 - acc: 1.0000 - val_loss: 0.1242 - val_acc: 1.0000\n",
            "Epoch 108/300\n",
            "56/56 [==============================] - 0s 234us/sample - loss: 0.1277 - acc: 1.0000 - val_loss: 0.1224 - val_acc: 1.0000\n",
            "Epoch 109/300\n",
            "56/56 [==============================] - 0s 391us/sample - loss: 0.1242 - acc: 1.0000 - val_loss: 0.1209 - val_acc: 1.0000\n",
            "Epoch 110/300\n",
            "56/56 [==============================] - 0s 288us/sample - loss: 0.1207 - acc: 1.0000 - val_loss: 0.1187 - val_acc: 1.0000\n",
            "Epoch 111/300\n",
            "56/56 [==============================] - 0s 410us/sample - loss: 0.1175 - acc: 1.0000 - val_loss: 0.1164 - val_acc: 1.0000\n",
            "Epoch 112/300\n",
            "56/56 [==============================] - 0s 322us/sample - loss: 0.1147 - acc: 1.0000 - val_loss: 0.1147 - val_acc: 1.0000\n",
            "Epoch 113/300\n",
            "56/56 [==============================] - 0s 386us/sample - loss: 0.1119 - acc: 1.0000 - val_loss: 0.1128 - val_acc: 1.0000\n",
            "Epoch 114/300\n",
            "56/56 [==============================] - 0s 324us/sample - loss: 0.1090 - acc: 1.0000 - val_loss: 0.1116 - val_acc: 1.0000\n",
            "Epoch 115/300\n",
            "56/56 [==============================] - 0s 279us/sample - loss: 0.1058 - acc: 1.0000 - val_loss: 0.1102 - val_acc: 1.0000\n",
            "Epoch 116/300\n",
            "56/56 [==============================] - 0s 438us/sample - loss: 0.1034 - acc: 1.0000 - val_loss: 0.1093 - val_acc: 1.0000\n",
            "Epoch 117/300\n",
            "56/56 [==============================] - 0s 275us/sample - loss: 0.1006 - acc: 1.0000 - val_loss: 0.1084 - val_acc: 1.0000\n",
            "Epoch 118/300\n",
            "56/56 [==============================] - 0s 323us/sample - loss: 0.0983 - acc: 1.0000 - val_loss: 0.1081 - val_acc: 1.0000\n",
            "Epoch 119/300\n",
            "56/56 [==============================] - 0s 248us/sample - loss: 0.0959 - acc: 1.0000 - val_loss: 0.1072 - val_acc: 1.0000\n",
            "Epoch 120/300\n",
            "56/56 [==============================] - 0s 268us/sample - loss: 0.0938 - acc: 1.0000 - val_loss: 0.1061 - val_acc: 1.0000\n",
            "Epoch 121/300\n",
            "56/56 [==============================] - 0s 211us/sample - loss: 0.0909 - acc: 1.0000 - val_loss: 0.1045 - val_acc: 1.0000\n",
            "Epoch 122/300\n",
            "56/56 [==============================] - 0s 294us/sample - loss: 0.0889 - acc: 1.0000 - val_loss: 0.1026 - val_acc: 1.0000\n",
            "Epoch 123/300\n",
            "56/56 [==============================] - 0s 355us/sample - loss: 0.0865 - acc: 1.0000 - val_loss: 0.1014 - val_acc: 1.0000\n",
            "Epoch 124/300\n",
            "56/56 [==============================] - 0s 293us/sample - loss: 0.0842 - acc: 1.0000 - val_loss: 0.1004 - val_acc: 1.0000\n",
            "Epoch 125/300\n",
            "56/56 [==============================] - 0s 247us/sample - loss: 0.0824 - acc: 1.0000 - val_loss: 0.0996 - val_acc: 1.0000\n",
            "Epoch 126/300\n",
            "56/56 [==============================] - 0s 297us/sample - loss: 0.0802 - acc: 1.0000 - val_loss: 0.0979 - val_acc: 1.0000\n",
            "Epoch 127/300\n",
            "56/56 [==============================] - 0s 419us/sample - loss: 0.0785 - acc: 1.0000 - val_loss: 0.0970 - val_acc: 1.0000\n",
            "Epoch 128/300\n",
            "56/56 [==============================] - 0s 360us/sample - loss: 0.0767 - acc: 1.0000 - val_loss: 0.0965 - val_acc: 1.0000\n",
            "Epoch 129/300\n",
            "56/56 [==============================] - 0s 296us/sample - loss: 0.0745 - acc: 1.0000 - val_loss: 0.0952 - val_acc: 1.0000\n",
            "Epoch 130/300\n",
            "56/56 [==============================] - 0s 286us/sample - loss: 0.0730 - acc: 1.0000 - val_loss: 0.0943 - val_acc: 1.0000\n",
            "Epoch 131/300\n",
            "56/56 [==============================] - 0s 328us/sample - loss: 0.0712 - acc: 1.0000 - val_loss: 0.0931 - val_acc: 1.0000\n",
            "Epoch 132/300\n",
            "56/56 [==============================] - 0s 402us/sample - loss: 0.0697 - acc: 1.0000 - val_loss: 0.0920 - val_acc: 1.0000\n",
            "Epoch 133/300\n",
            "56/56 [==============================] - 0s 332us/sample - loss: 0.0679 - acc: 1.0000 - val_loss: 0.0912 - val_acc: 1.0000\n",
            "Epoch 134/300\n",
            "56/56 [==============================] - 0s 361us/sample - loss: 0.0661 - acc: 1.0000 - val_loss: 0.0904 - val_acc: 1.0000\n",
            "Epoch 135/300\n",
            "56/56 [==============================] - 0s 256us/sample - loss: 0.0649 - acc: 1.0000 - val_loss: 0.0900 - val_acc: 1.0000\n",
            "Epoch 136/300\n",
            "56/56 [==============================] - 0s 365us/sample - loss: 0.0634 - acc: 1.0000 - val_loss: 0.0892 - val_acc: 1.0000\n",
            "Epoch 137/300\n",
            "56/56 [==============================] - 0s 384us/sample - loss: 0.0617 - acc: 1.0000 - val_loss: 0.0885 - val_acc: 1.0000\n",
            "Epoch 138/300\n",
            "56/56 [==============================] - 0s 365us/sample - loss: 0.0609 - acc: 1.0000 - val_loss: 0.0879 - val_acc: 1.0000\n",
            "Epoch 139/300\n",
            "56/56 [==============================] - 0s 335us/sample - loss: 0.0593 - acc: 1.0000 - val_loss: 0.0879 - val_acc: 1.0000\n",
            "Epoch 140/300\n",
            "56/56 [==============================] - 0s 286us/sample - loss: 0.0580 - acc: 1.0000 - val_loss: 0.0872 - val_acc: 1.0000\n",
            "Epoch 141/300\n",
            "56/56 [==============================] - 0s 318us/sample - loss: 0.0567 - acc: 1.0000 - val_loss: 0.0867 - val_acc: 1.0000\n",
            "Epoch 142/300\n",
            "56/56 [==============================] - 0s 348us/sample - loss: 0.0556 - acc: 1.0000 - val_loss: 0.0861 - val_acc: 1.0000\n",
            "Epoch 143/300\n",
            "56/56 [==============================] - 0s 255us/sample - loss: 0.0541 - acc: 1.0000 - val_loss: 0.0848 - val_acc: 1.0000\n",
            "Epoch 144/300\n",
            "56/56 [==============================] - 0s 262us/sample - loss: 0.0532 - acc: 1.0000 - val_loss: 0.0833 - val_acc: 1.0000\n",
            "Epoch 145/300\n",
            "56/56 [==============================] - 0s 282us/sample - loss: 0.0520 - acc: 1.0000 - val_loss: 0.0827 - val_acc: 1.0000\n",
            "Epoch 146/300\n",
            "56/56 [==============================] - 0s 229us/sample - loss: 0.0512 - acc: 1.0000 - val_loss: 0.0822 - val_acc: 1.0000\n",
            "Epoch 147/300\n",
            "56/56 [==============================] - 0s 247us/sample - loss: 0.0500 - acc: 1.0000 - val_loss: 0.0811 - val_acc: 1.0000\n",
            "Epoch 148/300\n",
            "56/56 [==============================] - 0s 299us/sample - loss: 0.0490 - acc: 1.0000 - val_loss: 0.0808 - val_acc: 1.0000\n",
            "Epoch 149/300\n",
            "56/56 [==============================] - 0s 254us/sample - loss: 0.0478 - acc: 1.0000 - val_loss: 0.0800 - val_acc: 1.0000\n",
            "Epoch 150/300\n",
            "56/56 [==============================] - 0s 301us/sample - loss: 0.0469 - acc: 1.0000 - val_loss: 0.0794 - val_acc: 1.0000\n",
            "Epoch 151/300\n",
            "56/56 [==============================] - 0s 335us/sample - loss: 0.0461 - acc: 1.0000 - val_loss: 0.0784 - val_acc: 1.0000\n",
            "Epoch 152/300\n",
            "56/56 [==============================] - 0s 252us/sample - loss: 0.0451 - acc: 1.0000 - val_loss: 0.0781 - val_acc: 1.0000\n",
            "Epoch 153/300\n",
            "56/56 [==============================] - 0s 315us/sample - loss: 0.0442 - acc: 1.0000 - val_loss: 0.0775 - val_acc: 1.0000\n",
            "Epoch 154/300\n",
            "56/56 [==============================] - 0s 423us/sample - loss: 0.0433 - acc: 1.0000 - val_loss: 0.0771 - val_acc: 1.0000\n",
            "Epoch 155/300\n",
            "56/56 [==============================] - 0s 283us/sample - loss: 0.0425 - acc: 1.0000 - val_loss: 0.0767 - val_acc: 1.0000\n",
            "Epoch 156/300\n",
            "56/56 [==============================] - 0s 293us/sample - loss: 0.0418 - acc: 1.0000 - val_loss: 0.0762 - val_acc: 1.0000\n",
            "Epoch 157/300\n",
            "56/56 [==============================] - 0s 425us/sample - loss: 0.0409 - acc: 1.0000 - val_loss: 0.0759 - val_acc: 1.0000\n",
            "Epoch 158/300\n",
            "56/56 [==============================] - 0s 324us/sample - loss: 0.0401 - acc: 1.0000 - val_loss: 0.0757 - val_acc: 1.0000\n",
            "Epoch 159/300\n",
            "56/56 [==============================] - 0s 296us/sample - loss: 0.0397 - acc: 1.0000 - val_loss: 0.0753 - val_acc: 1.0000\n",
            "Epoch 160/300\n",
            "56/56 [==============================] - 0s 351us/sample - loss: 0.0388 - acc: 1.0000 - val_loss: 0.0745 - val_acc: 1.0000\n",
            "Epoch 161/300\n",
            "56/56 [==============================] - 0s 400us/sample - loss: 0.0380 - acc: 1.0000 - val_loss: 0.0741 - val_acc: 1.0000\n",
            "Epoch 162/300\n",
            "56/56 [==============================] - 0s 273us/sample - loss: 0.0373 - acc: 1.0000 - val_loss: 0.0732 - val_acc: 1.0000\n",
            "Epoch 163/300\n",
            "56/56 [==============================] - 0s 309us/sample - loss: 0.0367 - acc: 1.0000 - val_loss: 0.0726 - val_acc: 1.0000\n",
            "Epoch 164/300\n",
            "56/56 [==============================] - 0s 315us/sample - loss: 0.0360 - acc: 1.0000 - val_loss: 0.0721 - val_acc: 1.0000\n",
            "Epoch 165/300\n",
            "56/56 [==============================] - 0s 231us/sample - loss: 0.0354 - acc: 1.0000 - val_loss: 0.0719 - val_acc: 1.0000\n",
            "Epoch 166/300\n",
            "56/56 [==============================] - 0s 284us/sample - loss: 0.0348 - acc: 1.0000 - val_loss: 0.0717 - val_acc: 1.0000\n",
            "Epoch 167/300\n",
            "56/56 [==============================] - 0s 267us/sample - loss: 0.0342 - acc: 1.0000 - val_loss: 0.0713 - val_acc: 1.0000\n",
            "Epoch 168/300\n",
            "56/56 [==============================] - 0s 258us/sample - loss: 0.0335 - acc: 1.0000 - val_loss: 0.0710 - val_acc: 1.0000\n",
            "Epoch 169/300\n",
            "56/56 [==============================] - 0s 266us/sample - loss: 0.0330 - acc: 1.0000 - val_loss: 0.0705 - val_acc: 1.0000\n",
            "Epoch 170/300\n",
            "56/56 [==============================] - 0s 335us/sample - loss: 0.0324 - acc: 1.0000 - val_loss: 0.0699 - val_acc: 1.0000\n",
            "Epoch 171/300\n",
            "56/56 [==============================] - 0s 316us/sample - loss: 0.0320 - acc: 1.0000 - val_loss: 0.0694 - val_acc: 1.0000\n",
            "Epoch 172/300\n",
            "56/56 [==============================] - 0s 261us/sample - loss: 0.0313 - acc: 1.0000 - val_loss: 0.0689 - val_acc: 1.0000\n",
            "Epoch 173/300\n",
            "56/56 [==============================] - 0s 356us/sample - loss: 0.0309 - acc: 1.0000 - val_loss: 0.0681 - val_acc: 1.0000\n",
            "Epoch 174/300\n",
            "56/56 [==============================] - 0s 323us/sample - loss: 0.0303 - acc: 1.0000 - val_loss: 0.0676 - val_acc: 1.0000\n",
            "Epoch 175/300\n",
            "56/56 [==============================] - 0s 267us/sample - loss: 0.0299 - acc: 1.0000 - val_loss: 0.0672 - val_acc: 1.0000\n",
            "Epoch 176/300\n",
            "56/56 [==============================] - 0s 258us/sample - loss: 0.0293 - acc: 1.0000 - val_loss: 0.0669 - val_acc: 1.0000\n",
            "Epoch 177/300\n",
            "56/56 [==============================] - 0s 265us/sample - loss: 0.0289 - acc: 1.0000 - val_loss: 0.0666 - val_acc: 1.0000\n",
            "Epoch 178/300\n",
            "56/56 [==============================] - 0s 258us/sample - loss: 0.0285 - acc: 1.0000 - val_loss: 0.0667 - val_acc: 1.0000\n",
            "Epoch 179/300\n",
            "56/56 [==============================] - 0s 231us/sample - loss: 0.0280 - acc: 1.0000 - val_loss: 0.0666 - val_acc: 1.0000\n",
            "Epoch 180/300\n",
            "56/56 [==============================] - 0s 266us/sample - loss: 0.0276 - acc: 1.0000 - val_loss: 0.0664 - val_acc: 1.0000\n",
            "Epoch 181/300\n",
            "56/56 [==============================] - 0s 239us/sample - loss: 0.0271 - acc: 1.0000 - val_loss: 0.0659 - val_acc: 1.0000\n",
            "Epoch 182/300\n",
            "56/56 [==============================] - 0s 220us/sample - loss: 0.0267 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 1.0000\n",
            "Epoch 183/300\n",
            "56/56 [==============================] - 0s 230us/sample - loss: 0.0262 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 1.0000\n",
            "Epoch 184/300\n",
            "56/56 [==============================] - 0s 288us/sample - loss: 0.0260 - acc: 1.0000 - val_loss: 0.0649 - val_acc: 1.0000\n",
            "Epoch 185/300\n",
            "56/56 [==============================] - 0s 257us/sample - loss: 0.0255 - acc: 1.0000 - val_loss: 0.0648 - val_acc: 1.0000\n",
            "Epoch 186/300\n",
            "56/56 [==============================] - 0s 280us/sample - loss: 0.0252 - acc: 1.0000 - val_loss: 0.0642 - val_acc: 1.0000\n",
            "Epoch 187/300\n",
            "56/56 [==============================] - 0s 265us/sample - loss: 0.0247 - acc: 1.0000 - val_loss: 0.0638 - val_acc: 1.0000\n",
            "Epoch 188/300\n",
            "56/56 [==============================] - 0s 303us/sample - loss: 0.0244 - acc: 1.0000 - val_loss: 0.0635 - val_acc: 1.0000\n",
            "Epoch 189/300\n",
            "56/56 [==============================] - 0s 323us/sample - loss: 0.0240 - acc: 1.0000 - val_loss: 0.0634 - val_acc: 1.0000\n",
            "Epoch 190/300\n",
            "56/56 [==============================] - 0s 244us/sample - loss: 0.0237 - acc: 1.0000 - val_loss: 0.0629 - val_acc: 1.0000\n",
            "Epoch 191/300\n",
            "56/56 [==============================] - 0s 223us/sample - loss: 0.0233 - acc: 1.0000 - val_loss: 0.0623 - val_acc: 1.0000\n",
            "Epoch 192/300\n",
            "56/56 [==============================] - 0s 247us/sample - loss: 0.0230 - acc: 1.0000 - val_loss: 0.0619 - val_acc: 1.0000\n",
            "Epoch 193/300\n",
            "56/56 [==============================] - 0s 248us/sample - loss: 0.0227 - acc: 1.0000 - val_loss: 0.0616 - val_acc: 1.0000\n",
            "Epoch 194/300\n",
            "56/56 [==============================] - 0s 245us/sample - loss: 0.0224 - acc: 1.0000 - val_loss: 0.0617 - val_acc: 1.0000\n",
            "Epoch 195/300\n",
            "56/56 [==============================] - 0s 243us/sample - loss: 0.0220 - acc: 1.0000 - val_loss: 0.0614 - val_acc: 1.0000\n",
            "Epoch 196/300\n",
            "56/56 [==============================] - 0s 229us/sample - loss: 0.0216 - acc: 1.0000 - val_loss: 0.0611 - val_acc: 1.0000\n",
            "Epoch 197/300\n",
            "56/56 [==============================] - 0s 391us/sample - loss: 0.0214 - acc: 1.0000 - val_loss: 0.0609 - val_acc: 1.0000\n",
            "Epoch 198/300\n",
            "56/56 [==============================] - 0s 241us/sample - loss: 0.0211 - acc: 1.0000 - val_loss: 0.0608 - val_acc: 1.0000\n",
            "Epoch 199/300\n",
            "56/56 [==============================] - 0s 222us/sample - loss: 0.0208 - acc: 1.0000 - val_loss: 0.0607 - val_acc: 1.0000\n",
            "Epoch 200/300\n",
            "56/56 [==============================] - 0s 268us/sample - loss: 0.0204 - acc: 1.0000 - val_loss: 0.0605 - val_acc: 1.0000\n",
            "Epoch 201/300\n",
            "56/56 [==============================] - 0s 298us/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 0.0603 - val_acc: 1.0000\n",
            "Epoch 202/300\n",
            "56/56 [==============================] - 0s 302us/sample - loss: 0.0199 - acc: 1.0000 - val_loss: 0.0599 - val_acc: 1.0000\n",
            "Epoch 203/300\n",
            "56/56 [==============================] - 0s 239us/sample - loss: 0.0196 - acc: 1.0000 - val_loss: 0.0597 - val_acc: 1.0000\n",
            "Epoch 204/300\n",
            "56/56 [==============================] - 0s 216us/sample - loss: 0.0194 - acc: 1.0000 - val_loss: 0.0597 - val_acc: 1.0000\n",
            "Epoch 205/300\n",
            "56/56 [==============================] - 0s 217us/sample - loss: 0.0191 - acc: 1.0000 - val_loss: 0.0593 - val_acc: 1.0000\n",
            "Epoch 206/300\n",
            "56/56 [==============================] - 0s 205us/sample - loss: 0.0188 - acc: 1.0000 - val_loss: 0.0590 - val_acc: 1.0000\n",
            "Epoch 207/300\n",
            "56/56 [==============================] - 0s 292us/sample - loss: 0.0186 - acc: 1.0000 - val_loss: 0.0586 - val_acc: 1.0000\n",
            "Epoch 208/300\n",
            "56/56 [==============================] - 0s 317us/sample - loss: 0.0184 - acc: 1.0000 - val_loss: 0.0586 - val_acc: 1.0000\n",
            "Epoch 209/300\n",
            "56/56 [==============================] - 0s 282us/sample - loss: 0.0181 - acc: 1.0000 - val_loss: 0.0586 - val_acc: 1.0000\n",
            "Epoch 210/300\n",
            "56/56 [==============================] - 0s 417us/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 0.0585 - val_acc: 1.0000\n",
            "Epoch 211/300\n",
            "56/56 [==============================] - 0s 309us/sample - loss: 0.0176 - acc: 1.0000 - val_loss: 0.0583 - val_acc: 1.0000\n",
            "Epoch 212/300\n",
            "56/56 [==============================] - 0s 293us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 0.0582 - val_acc: 1.0000\n",
            "Epoch 213/300\n",
            "56/56 [==============================] - 0s 297us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 0.0579 - val_acc: 1.0000\n",
            "Epoch 214/300\n",
            "56/56 [==============================] - 0s 311us/sample - loss: 0.0169 - acc: 1.0000 - val_loss: 0.0577 - val_acc: 1.0000\n",
            "Epoch 215/300\n",
            "56/56 [==============================] - 0s 318us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 0.0574 - val_acc: 1.0000\n",
            "Epoch 216/300\n",
            "56/56 [==============================] - 0s 353us/sample - loss: 0.0166 - acc: 1.0000 - val_loss: 0.0573 - val_acc: 1.0000\n",
            "Epoch 217/300\n",
            "56/56 [==============================] - 0s 233us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 0.0572 - val_acc: 1.0000\n",
            "Epoch 218/300\n",
            "56/56 [==============================] - 0s 207us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 0.0570 - val_acc: 1.0000\n",
            "Epoch 219/300\n",
            "56/56 [==============================] - 0s 290us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 0.0569 - val_acc: 1.0000\n",
            "Epoch 220/300\n",
            "56/56 [==============================] - 0s 264us/sample - loss: 0.0157 - acc: 1.0000 - val_loss: 0.0566 - val_acc: 1.0000\n",
            "Epoch 221/300\n",
            "56/56 [==============================] - 0s 326us/sample - loss: 0.0156 - acc: 1.0000 - val_loss: 0.0564 - val_acc: 1.0000\n",
            "Epoch 222/300\n",
            "56/56 [==============================] - 0s 397us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 0.0561 - val_acc: 1.0000\n",
            "Epoch 223/300\n",
            "56/56 [==============================] - 0s 226us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.0559 - val_acc: 1.0000\n",
            "Epoch 224/300\n",
            "56/56 [==============================] - 0s 217us/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 0.0557 - val_acc: 1.0000\n",
            "Epoch 225/300\n",
            "56/56 [==============================] - 0s 227us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.0555 - val_acc: 1.0000\n",
            "Epoch 226/300\n",
            "56/56 [==============================] - 0s 312us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.0554 - val_acc: 1.0000\n",
            "Epoch 227/300\n",
            "56/56 [==============================] - 0s 376us/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 0.0555 - val_acc: 1.0000\n",
            "Epoch 228/300\n",
            "56/56 [==============================] - 0s 241us/sample - loss: 0.0142 - acc: 1.0000 - val_loss: 0.0553 - val_acc: 1.0000\n",
            "Epoch 229/300\n",
            "56/56 [==============================] - 0s 306us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.0552 - val_acc: 1.0000\n",
            "Epoch 230/300\n",
            "56/56 [==============================] - 0s 235us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.0551 - val_acc: 1.0000\n",
            "Epoch 231/300\n",
            "56/56 [==============================] - 0s 273us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.0549 - val_acc: 1.0000\n",
            "Epoch 232/300\n",
            "56/56 [==============================] - 0s 334us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 0.0547 - val_acc: 1.0000\n",
            "Epoch 233/300\n",
            "56/56 [==============================] - 0s 333us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 0.0546 - val_acc: 1.0000\n",
            "Epoch 234/300\n",
            "56/56 [==============================] - 0s 267us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 0.0545 - val_acc: 1.0000\n",
            "Epoch 235/300\n",
            "56/56 [==============================] - 0s 242us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.0544 - val_acc: 1.0000\n",
            "Epoch 236/300\n",
            "56/56 [==============================] - 0s 208us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.0542 - val_acc: 1.0000\n",
            "Epoch 237/300\n",
            "56/56 [==============================] - 0s 218us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.0540 - val_acc: 1.0000\n",
            "Epoch 238/300\n",
            "56/56 [==============================] - 0s 259us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.0537 - val_acc: 1.0000\n",
            "Epoch 239/300\n",
            "56/56 [==============================] - 0s 271us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.0536 - val_acc: 1.0000\n",
            "Epoch 240/300\n",
            "56/56 [==============================] - 0s 268us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.0535 - val_acc: 1.0000\n",
            "Epoch 241/300\n",
            "56/56 [==============================] - 0s 263us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.0535 - val_acc: 1.0000\n",
            "Epoch 242/300\n",
            "56/56 [==============================] - 0s 251us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.0534 - val_acc: 1.0000\n",
            "Epoch 243/300\n",
            "56/56 [==============================] - 0s 291us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.0535 - val_acc: 1.0000\n",
            "Epoch 244/300\n",
            "56/56 [==============================] - 0s 302us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.0535 - val_acc: 1.0000\n",
            "Epoch 245/300\n",
            "56/56 [==============================] - 0s 364us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.0533 - val_acc: 1.0000\n",
            "Epoch 246/300\n",
            "56/56 [==============================] - 0s 306us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0531 - val_acc: 1.0000\n",
            "Epoch 247/300\n",
            "56/56 [==============================] - 0s 257us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.0530 - val_acc: 1.0000\n",
            "Epoch 248/300\n",
            "56/56 [==============================] - 0s 275us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.0528 - val_acc: 1.0000\n",
            "Epoch 249/300\n",
            "56/56 [==============================] - 0s 323us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.0527 - val_acc: 1.0000\n",
            "Epoch 250/300\n",
            "56/56 [==============================] - 0s 264us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.0527 - val_acc: 1.0000\n",
            "Epoch 251/300\n",
            "56/56 [==============================] - 0s 237us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.0527 - val_acc: 1.0000\n",
            "Epoch 252/300\n",
            "56/56 [==============================] - 0s 206us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.0526 - val_acc: 1.0000\n",
            "Epoch 253/300\n",
            "56/56 [==============================] - 0s 311us/sample - loss: 0.0108 - acc: 1.0000 - val_loss: 0.0524 - val_acc: 1.0000\n",
            "Epoch 254/300\n",
            "56/56 [==============================] - 0s 279us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.0523 - val_acc: 1.0000\n",
            "Epoch 255/300\n",
            "56/56 [==============================] - 0s 278us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0524 - val_acc: 1.0000\n",
            "Epoch 256/300\n",
            "56/56 [==============================] - 0s 293us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.0522 - val_acc: 1.0000\n",
            "Epoch 257/300\n",
            "56/56 [==============================] - 0s 261us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.0522 - val_acc: 1.0000\n",
            "Epoch 258/300\n",
            "56/56 [==============================] - 0s 326us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.0521 - val_acc: 1.0000\n",
            "Epoch 259/300\n",
            "56/56 [==============================] - 0s 410us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0519 - val_acc: 1.0000\n",
            "Epoch 260/300\n",
            "56/56 [==============================] - 0s 291us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.0517 - val_acc: 1.0000\n",
            "Epoch 261/300\n",
            "56/56 [==============================] - 0s 267us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.0516 - val_acc: 1.0000\n",
            "Epoch 262/300\n",
            "56/56 [==============================] - 0s 245us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.0516 - val_acc: 1.0000\n",
            "Epoch 263/300\n",
            "56/56 [==============================] - 0s 255us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0516 - val_acc: 1.0000\n",
            "Epoch 264/300\n",
            "56/56 [==============================] - 0s 286us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0515 - val_acc: 1.0000\n",
            "Epoch 265/300\n",
            "56/56 [==============================] - 0s 344us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.0514 - val_acc: 1.0000\n",
            "Epoch 266/300\n",
            "56/56 [==============================] - 0s 314us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0513 - val_acc: 1.0000\n",
            "Epoch 267/300\n",
            "56/56 [==============================] - 0s 342us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.0513 - val_acc: 1.0000\n",
            "Epoch 268/300\n",
            "56/56 [==============================] - 0s 264us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.0514 - val_acc: 1.0000\n",
            "Epoch 269/300\n",
            "56/56 [==============================] - 0s 294us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.0513 - val_acc: 1.0000\n",
            "Epoch 270/300\n",
            "56/56 [==============================] - 0s 329us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.0513 - val_acc: 1.0000\n",
            "Epoch 271/300\n",
            "56/56 [==============================] - 0s 218us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.0512 - val_acc: 1.0000\n",
            "Epoch 272/300\n",
            "56/56 [==============================] - 0s 277us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.0510 - val_acc: 1.0000\n",
            "Epoch 273/300\n",
            "56/56 [==============================] - 0s 214us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0508 - val_acc: 1.0000\n",
            "Epoch 274/300\n",
            "56/56 [==============================] - 0s 273us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0507 - val_acc: 1.0000\n",
            "Epoch 275/300\n",
            "56/56 [==============================] - 0s 279us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0505 - val_acc: 1.0000\n",
            "Epoch 276/300\n",
            "56/56 [==============================] - 0s 294us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.0505 - val_acc: 1.0000\n",
            "Epoch 277/300\n",
            "56/56 [==============================] - 0s 349us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0505 - val_acc: 1.0000\n",
            "Epoch 278/300\n",
            "56/56 [==============================] - 0s 269us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0505 - val_acc: 1.0000\n",
            "Epoch 279/300\n",
            "56/56 [==============================] - 0s 359us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0506 - val_acc: 1.0000\n",
            "Epoch 280/300\n",
            "56/56 [==============================] - 0s 338us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0505 - val_acc: 1.0000\n",
            "Epoch 281/300\n",
            "56/56 [==============================] - 0s 279us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0502 - val_acc: 1.0000\n",
            "Epoch 282/300\n",
            "56/56 [==============================] - 0s 269us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0501 - val_acc: 1.0000\n",
            "Epoch 283/300\n",
            "56/56 [==============================] - 0s 222us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0500 - val_acc: 1.0000\n",
            "Epoch 284/300\n",
            "56/56 [==============================] - 0s 249us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0500 - val_acc: 1.0000\n",
            "Epoch 285/300\n",
            "56/56 [==============================] - 0s 249us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0498 - val_acc: 1.0000\n",
            "Epoch 286/300\n",
            "56/56 [==============================] - 0s 314us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0497 - val_acc: 1.0000\n",
            "Epoch 287/300\n",
            "56/56 [==============================] - 0s 221us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0496 - val_acc: 1.0000\n",
            "Epoch 288/300\n",
            "56/56 [==============================] - 0s 288us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0497 - val_acc: 1.0000\n",
            "Epoch 289/300\n",
            "56/56 [==============================] - 0s 296us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0499 - val_acc: 1.0000\n",
            "Epoch 290/300\n",
            "56/56 [==============================] - 0s 308us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0499 - val_acc: 1.0000\n",
            "Epoch 291/300\n",
            "56/56 [==============================] - 0s 325us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0500 - val_acc: 1.0000\n",
            "Epoch 292/300\n",
            "56/56 [==============================] - 0s 273us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0499 - val_acc: 1.0000\n",
            "Epoch 293/300\n",
            "56/56 [==============================] - 0s 328us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0498 - val_acc: 1.0000\n",
            "Epoch 294/300\n",
            "56/56 [==============================] - 0s 261us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0496 - val_acc: 1.0000\n",
            "Epoch 295/300\n",
            "56/56 [==============================] - 0s 229us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0496 - val_acc: 1.0000\n",
            "Epoch 296/300\n",
            "56/56 [==============================] - 0s 401us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0494 - val_acc: 1.0000\n",
            "Epoch 297/300\n",
            "56/56 [==============================] - 0s 288us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0493 - val_acc: 1.0000\n",
            "Epoch 298/300\n",
            "56/56 [==============================] - 0s 255us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0493 - val_acc: 1.0000\n",
            "Epoch 299/300\n",
            "56/56 [==============================] - 0s 257us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0493 - val_acc: 1.0000\n",
            "Epoch 300/300\n",
            "56/56 [==============================] - 0s 337us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0492 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXAL7dKhhLeM",
        "colab_type": "code",
        "outputId": "3e0ccff1-ebea-428a-e719-e02c3d7c7865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Model accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFAoiItJNoSAiIt0UCiIi0u3/A/UngkAhWut7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96NcMe3zhSEy",
        "colab_type": "code",
        "outputId": "a987fc93-57e0-4644-bad7-12e1b80b23d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Model Loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EA9F3tS3j7XB",
        "colab_type": "code",
        "outputId": "15457fa0-2a1f-4377-94c0-56ba3fd82f19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# evaluate the model\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc: 96.77%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRAen8MB2kpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
