{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "plot_diff_color_final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymt2wBnZdHpn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from numpy.random import multivariate_normal, shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPToPFnTdO1e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_synthetic_2dpoints(mean, cov, npoints):\n",
        "    points = multivariate_normal(mean, cov, npoints).T\n",
        "    return points"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIH4UjRQdSL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate random covariance\n",
        "def rcov(r=9):\n",
        "    np.random.seed(r)\n",
        "    x = np.random.uniform(-0.35, 0.35, size = (2, 2))\n",
        "    x = np.dot(x, x.transpose())\n",
        "    return x "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqY6lL2pfEgF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate synthetic data \n",
        "def gen_set1():\n",
        "    # 2 clusters\n",
        "    cov1 = [[0.02, 0], [0, 0.15]]\n",
        "    cov2 = [[0.02, 0], [0, 0.25]]\n",
        "    \n",
        "    means = [[-1.00, +1.10], \n",
        "             [+0.25, -0.75]]\n",
        "    cov = [cov1, rcov()]\n",
        "\n",
        "    npoints = [75, 90]\n",
        "       \n",
        "    p1 = generate_synthetic_2dpoints(means[0], cov[0], npoints[0])\n",
        "    p2 = generate_synthetic_2dpoints(means[1], cov[1], npoints[1])\n",
        "    pa = np.hstack((p1, p2))\n",
        "    pa = pa.T\n",
        "    \n",
        "    # 3 clusters\n",
        "    means = [[-0.50, -0.00], \n",
        "             [+1.65, -1.50], \n",
        "             [+1.50, +0.50]]\n",
        "    cov = [cov1, rcov(), rcov()]\n",
        "    npoints = [40, 60, 70]\n",
        "\n",
        "    p1 = generate_synthetic_2dpoints(means[0], cov[0], npoints[0])\n",
        "    p2 = generate_synthetic_2dpoints(means[1], cov[1], npoints[1])\n",
        "    p3 = generate_synthetic_2dpoints(means[2], cov[2], npoints[2])\n",
        "    pb = np.hstack((p1, p2, p3))\n",
        "    pb = pb.T\n",
        "\n",
        "    # 4 clusters\n",
        "    means = [[+1.70, -1.15], \n",
        "             [+2.15, +1.10], \n",
        "             [-1.20, +1.50],\n",
        "             [-1.20, -0.2]]\n",
        "    cov = [rcov() for i in range(4)]\n",
        "    npoints = [50, 75, 60, 95]\n",
        "\n",
        "    p1 = generate_synthetic_2dpoints(means[0], cov[0], npoints[0])\n",
        "    p2 = generate_synthetic_2dpoints(means[1], cov[1], npoints[1])\n",
        "    p3 = generate_synthetic_2dpoints(means[2], cov[2], npoints[2])\n",
        "    p4 = generate_synthetic_2dpoints(means[3], cov[3], npoints[3])\n",
        "    pc = np.hstack((p1, p2, p3, p4))\n",
        "    pc = pc.T\n",
        "\n",
        "\n",
        "    # 5 clusters \n",
        "    means = [[-2.1, -1.5], \n",
        "             [-2.5, +1.5], \n",
        "             [+1.8, -1.6],\n",
        "             [+2.3, +1.7],\n",
        "             [+0.1, +0.1]]\n",
        "\n",
        "    cov = [cov1, rcov(), rcov(), cov2, rcov()]\n",
        "    npoints = [90, 55, 70, 40, 60]\n",
        "    p1 = generate_synthetic_2dpoints(means[0], cov[0], npoints[0])\n",
        "    p2 = generate_synthetic_2dpoints(means[1], cov[1], npoints[1])\n",
        "    p3 = generate_synthetic_2dpoints(means[2], cov[2], npoints[2])\n",
        "    p4 = generate_synthetic_2dpoints(means[3], cov[3], npoints[3])\n",
        "    p5 = generate_synthetic_2dpoints(means[4], cov[4], npoints[4])\n",
        "    pd = np.hstack((p1, p2, p3, p4, p5))\n",
        "    pd = pd.T\n",
        "\n",
        "    return [pa, pb, pc, pd]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbCyOQk0fXrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load 4 data sets of 2d points of clusters [2, 3, 4, 5] \n",
        "pointset = gen_set1()\n",
        "\n",
        "samples1, samples2, samples3, samples4 = pointset[0], pointset[1], pointset[2], pointset[3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcMqkrCwhBGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Calculate shortest distance between 2 data points\n",
        "def Euclidean_distance(one, two):\n",
        "\n",
        "    squared_distance = 0\n",
        "    \n",
        "    for i in range(len(one)):\n",
        "\n",
        "            squared_distance += ((one[i] - two[i])**2)\n",
        "\n",
        "    ed = math.sqrt(squared_distance)\n",
        "\n",
        "    return ed;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBYqGccFhCik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def k_means_train(dataset, cluster_number, iteration_number):\n",
        "  \n",
        "  #create random centroids\n",
        "  centroids = np.random.randn(cluster_number, dataset.shape[1])\n",
        "  \n",
        "  ###\n",
        "  #list contains sum of squared errors after iterations\n",
        "  sum_of_squared_error = []\n",
        "  ###\n",
        "  \n",
        "  for i in range(iteration_number):\n",
        "      \n",
        "      ###\n",
        "      squaredError = 0\n",
        "      ###\n",
        "      clusters = []\n",
        "      \n",
        "      #iterate over the dataset\n",
        "      for p, point in enumerate(dataset):\n",
        "\n",
        "          current_distance = 0\n",
        "          best_distance = 100\n",
        "          \n",
        "          for c, center in enumerate(centroids):\n",
        "          \n",
        "              current_distance = Euclidean_distance(point, center)\n",
        "              if (current_distance < best_distance):\n",
        "                  best_distance = current_distance\n",
        "                  cluster_index = c\n",
        "                  \n",
        "          #put a point with exact cluster number in a list, \n",
        "          #act_data = [x, y, cluster_index]\n",
        "          act_data = point\n",
        "          act_data = np.append(act_data, cluster_index)\n",
        "          clusters.append(act_data)\n",
        "          \n",
        "      #numpy array for plotting datas\n",
        "      np_clusters = np.asarray(clusters)\n",
        "      clusters.clear()\n",
        "      \n",
        "      act_cluster = []\n",
        "      \n",
        "      #iterate over centroids, determine mean of cluster groups and update new \n",
        "      #place of centroid points\n",
        "      for c, centroid in enumerate(centroids):\n",
        "          \n",
        "          for cl, cluster in enumerate(np_clusters):\n",
        "              \n",
        "              if (cluster[2] == c):\n",
        "                  \n",
        "                  act_cluster.append(cluster)\n",
        "          \n",
        "          np_act_cluster = np.asarray(act_cluster)\n",
        "          mean = np.mean(np_act_cluster, axis = 0)\n",
        "          \n",
        "          ###\n",
        "          #call squared_error function what gets datas of actual cluster group, \n",
        "          #mean of this group and returns sum of squared errors \n",
        "          squaredError += squared_error(np_act_cluster, mean)\n",
        "          ###\n",
        "          \n",
        "          centroid[0] = mean[0]\n",
        "          centroid[1] = mean[1]\n",
        "          act_cluster.clear()\n",
        "      \n",
        "      ###\n",
        "      sum_of_squared_error.append(squaredError)\n",
        "      ###\n",
        "  return np_clusters, centroids, sum_of_squared_error\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKqUAzD1lX6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotting_results(labels, centroids):\n",
        "      \n",
        "    #array for plotting cluster groups in different colors\n",
        "    colors = ['b', 'g', 'c', 'm', 'y', 'k', 'w', 'r']\n",
        "    \n",
        "    act_cluster = []\n",
        "    \n",
        "    #iterate over centroids to plot cluster groups\n",
        "    for c, centroid in enumerate(centroids):\n",
        "          \n",
        "        for cl, cluster in enumerate(labels):\n",
        "            \n",
        "            if (cluster[2] == c):\n",
        "                  \n",
        "                act_cluster.append(cluster)\n",
        "          \n",
        "        np_act_cluster = np.asarray(act_cluster)\n",
        "        \n",
        "        plt.scatter(np_act_cluster[:,0], np_act_cluster[:,1], c=colors[c], s=5)\n",
        "        \n",
        "        act_cluster.clear()\n",
        "     \n",
        "    #plotting final centroid points\n",
        "    for z, centroid in enumerate(centroids):\n",
        "        \n",
        "        plt.scatter(centroids[z][0], centroids[z][1], marker='*', c='r', s=150)\n",
        "    \n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR_ItXN_SCGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###\n",
        "def squared_error(cluster, centroid):\n",
        "    \n",
        "    sse = 0\n",
        "    \n",
        "    for d, datapoint in enumerate(cluster):\n",
        "        \n",
        "        sse += math.sqrt(datapoint - centroid)\n",
        "    \n",
        "    return sse\n",
        "###       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN41JqE5hy2B",
        "colab_type": "code",
        "outputId": "4958cb40-047d-4fdc-9a05-489f4fa514a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "np.random.shuffle(samples1)\n",
        "\n",
        "labels, centroids, sse = k_means_train(samples1, 2, 100)\n",
        "\n",
        "plotting_results(labels, centroids)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-26007837d1f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_means_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplotting_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-9a3a6abf1fef>\u001b[0m in \u001b[0;36mk_means_train\u001b[0;34m(dataset, cluster_number, iteration_number)\u001b[0m\n\u001b[1;32m     54\u001b[0m           \u001b[0;31m#call squared_error function what gets datas of actual cluster group,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m           \u001b[0;31m#mean of this group and returns sum of squared errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m           \u001b[0msquaredError\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msquared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_act_cluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m           \u001b[0mcentroid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-a3564380d864>\u001b[0m in \u001b[0;36msquared_error\u001b[0;34m(cluster, centroid)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatapoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0msse\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapoint\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcentroid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NW0PwK5mnsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.shuffle(samples2)\n",
        "\n",
        "labels, centroids, sse = k_means_train(samples2, 3, 100)\n",
        "\n",
        "plotting_results(labels, centroids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOb616-Lhpw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.shuffle(samples3)\n",
        "\n",
        "labels, centroids, sse = k_means_train(samples3, 4, 100)\n",
        "\n",
        "plotting_results(labels, centroids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHwqv2wzhqdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.shuffle(samples4)\n",
        "\n",
        "labels, centroids, sse = k_means_train(samples4, 5, 100)\n",
        "\n",
        "plotting_results(labels, centroids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMJJSYIqRHxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}